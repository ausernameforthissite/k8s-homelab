---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-k8s-container-cpu-throttling
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: k8s-container-cpu-throttling
    rules:
    - alert: ContainerCPUThrottlingHigh
      annotations:
        description: >-
          {{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}:
          {{ $value | humanizePercentage }}
        summary: Container throttling rate is above 30%
      expr: |-
        (
          increase(container_cpu_cfs_throttled_periods_total[5m])
          /
          increase(container_cpu_cfs_periods_total[5m])
        ) > 0.3
      for: 15m
      labels:
        severity: info
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-k8s-container-memory
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-k8s-container-memory
    rules:
    - alert: ContainerRSSCloseToLimit
      annotations:
        description: >-
          {{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}:
          {{ $value | humanizePercentage }}
        summary: Container RSS is above 90% of memory limit
      expr: |-
        container_memory_rss / container_spec_memory_limit_bytes{} > 0.9
        and
        container_memory_working_set_bytes / container_spec_memory_limit_bytes{} > 0.97
        and
        container_spec_memory_limit_bytes != 0
      for: 5m
      labels:
        severity: warning
    - alert: ContainerRSSAtLimit
      annotations:
        description: >-
          {{ $labels.namespace }}/{{ $labels.pod }}/{{ $labels.container }}:
          {{ $value | humanizePercentage }}
        summary: Container RSS is above 97% of memory limit
      expr: |-
        container_memory_rss / container_spec_memory_limit_bytes{} > 0.97
        and
        container_memory_working_set_bytes / container_spec_memory_limit_bytes{} > 0.99
        and
        container_spec_memory_limit_bytes != 0
      for: 0m
      labels:
        severity: warning
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-kubelet-system
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: kubelet-system
    rules:
    - alert: KubeletPlegDurationHigh
      annotations:
        description: >-
          node {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet PLEG relist 99th percentile is above 0.5s
      expr: max_over_time(kubelet_pleg_relist_duration_seconds:quantile_irate{quantile="0.99"}[1m]) >= 0.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeletPodStartUpLatencyHigh
      annotations:
        description: >-
          {{ $labels.instance }}:
          operation {{ $labels.operation_type }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet Pod startup latency is above 15 seconds
      expr: |-
        histogram_quantile(0.99,
          rate(kubelet_pod_worker_duration_seconds_bucket[5m])
        ) > 15
      for: 15m
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet client certificate expires in less than 7 days
      expr: kubelet_certificate_manager_client_ttl_seconds < (7 * 24 * 60 * 60)
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet client certificate expires in less than 24 hours
      expr: kubelet_certificate_manager_client_ttl_seconds < (24 * 60 * 60)
      labels:
        severity: critical
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet server certificate expires in less than 7 days
      expr: kubelet_certificate_manager_server_ttl_seconds < (7 * 24 * 60 * 60)
      labels:
        severity: warning
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Kubelet server certificate expires in less than 24 hours
      expr: kubelet_certificate_manager_server_ttl_seconds < (24 * 60 * 60)
      labels:
        severity: critical
    - alert: KubeletClientCertificateRenewalErrors
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }} errors
        summary: Kubelet has failed to renew its client certificate
      expr: increase(kubelet_certificate_manager_client_expiration_renew_errors[15m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletServerCertificateRenewalErrors
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }} errors
        summary: Kubelet has failed to renew its server certificate
      expr: increase(kubelet_server_expiration_renew_errors[15m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletDown
      annotations:
        description: >-
          No kubelets found
        summary: Kubelet has disappeared from Prometheus target discovery
      # (up == 0) alert should be located elsewhere
      # this one just catches "nothing found at all" situation
      expr: max by(cluster_type, cluster) (up{job="kubelet-main"}) == 0
      for: 15m
      labels:
        severity: critical
