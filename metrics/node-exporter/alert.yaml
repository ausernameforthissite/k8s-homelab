---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-node-exporter-filesystem
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-node-exporter-filesystem
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          space left: {{ $value | humanizePercentage }}
        summary: Filesystem is predicted to run out of space within the next 24 hours
      expr: |-
        (
          node_filesystem_avail_bytes{fstype!="",mountpoint!=""} / node_filesystem_size_bytes
        and
          predict_linear(node_filesystem_avail_bytes[6h], 24*60*60) < 0
        and
          node_filesystem_readonly == 0
        )
      for: 30m
      labels:
        severity: warning
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          space left: {{ $value | humanizePercentage }}
        summary: Filesystem is predicted to run out of space within the next 4 hours
      expr: |-
        (
          node_filesystem_avail_bytes{fstype!="",mountpoint!=""} / node_filesystem_size_bytes
        and
          predict_linear(node_filesystem_avail_bytes[6h], 4*60*60) < 0
        and
          node_filesystem_readonly == 0
        )
      for: 30m
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          {{ $value | humanizePercentage }}
        summary: Filesystem has less than 10% available space left
      expr: |-
        (
          node_filesystem_avail_bytes{fstype!="",mountpoint!=""}
          /
          node_filesystem_size_bytes < 0.1
        and
          node_filesystem_readonly == 0
        )
      for: 30m
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          {{ $value | humanizePercentage }}
        summary: Filesystem has less than 3% space left
      expr: |-
        (
          node_filesystem_avail_bytes{fstype!="",mountpoint!=""} / node_filesystem_size_bytes < 0.03
        and
          node_filesystem_readonly == 0
        )
      for: 30m
      labels:
        severity: critical
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          available inodes: {{ $value | humanizePercentage }}
        summary: Filesystem is predicted to run out of inodes within the next 24 hours
      expr: |-
        (
          node_filesystem_files_free{fstype!="",mountpoint!=""} / node_filesystem_files
        and
          predict_linear(node_filesystem_files_free[6h], 24*60*60) < 0
        and
          node_filesystem_readonly == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          available inodes: {{ $value | humanizePercentage }}
        summary: Filesystem is predicted to run out of inodes within the next 4 hours
      expr: |-
        (
          node_filesystem_files_free{fstype!="",mountpoint!=""} / node_filesystem_files < 0.2
        and
          predict_linear(node_filesystem_files_free[6h], 4*60*60) < 0
        and
          node_filesystem_readonly == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          {{ $value | humanizePercentage }}
        summary: Filesystem has less than 5% inodes left
      expr: |-
        (
          node_filesystem_files_free{fstype!="",mountpoint!=""} / node_filesystem_files < 0.05
        and
          node_filesystem_readonly == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: >-
          {{ $labels.instance }}: {{ $labels.device }} mounted on {{ $labels.mountpoint }}:
          {{ $value | humanizePercentage }}
        summary: Filesystem has less than 3% inodes left
      expr: |-
        (
          node_filesystem_files_free{fstype!="",mountpoint!=""} / node_filesystem_files < 0.03
        and
          node_filesystem_readonly == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeRaidFailed # TODO remove this?
      annotations:
        description: >-
          {{ $labels.instance }}:
          RAID array {{ $labels.device }}:
          missing {{ $value | humanizePercentage }} drives
        summary: RAID Array has failed
      expr: |-
        (
          node_md_disks_required{device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}
          -
          ignoring (state) (node_md_disks{state="active"})
        ) > 0
      for: 15m
      labels:
        severity: critical
    - alert: NodeRaidDiskFailure # TODO remove this?
      annotations:
        description: >-
          {{ $labels.instance }}:
          device {{ $labels.device }}
        summary: Failed device in RAID array
      expr: node_md_disks{state="failed", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"} > 0
      labels:
        severity: warning
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-node-exporter-network
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-node-exporter-network
    rules:
    - alert: NodeNetworkReceiveErrors
      annotations:
        description: >-
          {{ $labels.instance }}:
          interface {{ $labels.device }}
          {{ $value | humanizePercentage }}
        summary: More than 1% of receive errors on network interface
      expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
      for: 30m
      labels:
        severity: warning
    - alert: NodeNetworkTransmitErrors
      annotations:
        description: >-
          {{ $labels.instance }}:
          interface {{ $labels.device }}
          {{ $value | humanizePercentage }}
        summary: More than 1% of transmit errors on network interface
      expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
    - alert: NodeHighNumberConntrackEntriesUsed
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        summary: More than 75% of conntrack are used
      expr: (node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75
      labels:
        severity: warning
    - alert: NodeNetworkInterfaceFlapping
      annotations:
        description: >-
          {{ $labels.instance }}:
          interface {{ $labels.device }}:
          {{ $value }} times
        summary: Network interface flipped more than 2 times over the last 10 minutes
      expr: changes(node_network_up{device!~"veth.+"}[10m]) > 2
      for: 2m
      labels:
        severity: warning
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-node-exporter-misc
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-node-exporter-misc
    rules:
    - alert: NodeTextFileCollectorScrapeError
      annotations:
        description: >-
          {{ $labels.instance }}
        summary: Node Exporter text file collector failed to scrape
      expr: node_textfile_scrape_error == 1
      labels:
        severity: warning
    - alert: NodeClockSkewDetected
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizeDuration }}
        summary: Clock is out of sync by more than 50ms
      expr: |-
        (
          node_timex_offset_seconds > 0.05
        and
          deriv(node_timex_offset_seconds[5m]) >= 0
        )
        or
        (
          node_timex_offset_seconds < -0.05
        and
          deriv(node_timex_offset_seconds[5m]) <= 0
        )
      for: 10m
      labels:
        severity: warning
    - alert: NodeClockNotSynchronizing
      annotations:
        description: >-
          {{ $labels.instance }}
        summary: Clock not synchronizing
      expr: |-
        min_over_time(node_timex_sync_status{}[5m]) == 0
        and
        node_timex_maxerror_seconds{} >= 16
      for: 10m
      labels:
        severity: warning
    - alert: NodeClockTimestampMismatch
      annotations:
        description: >-
          {{ $labels.instance }}
        summary: Node reported timestamp differs from scrape timestamp by more than 5 seconds
      expr: |-
        abs(node_time_seconds - timestamp(node_time_seconds)) > 5
      for: 10m
      labels:
        severity: warning
    - alert: NodeEdacCorrectable
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }}
        summary: Node encountered memory errors that were automatically corrected
      expr: |-
        increase(node_edac_correctable_errors_total[1h]) != 0
      for: 0m
      labels:
        severity: critical
    - alert: NodeEdacUncorrectable
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }}
        summary: Node encountered memory errors that could not be corrected
      expr: |-
        increase(node_edac_uncorrectable_errors_total[1h]) != 0
      for: 0m
      labels:
        severity: critical
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-node-exporter-system
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-node-exporter-system
    rules:
    - alert: NodeFileDescriptorLimit
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: File descriptors usage is above 70%
      expr: |-
        (
          node_filefd_allocated / node_filefd_maximum
        ) > 0.7
      for: 15m
      labels:
        severity: warning
    - alert: NodeFileDescriptorLimit
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: File descriptors usage is above 90%
      expr: |-
        (
          node_filefd_allocated / node_filefd_maximum
        ) > 0.9
      for: 15m
      labels:
        severity: critical
    - alert: NodeCPUHighUsage
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        summary: High CPU usage
      expr: |-
        avg without (cpu) (
          sum without(mode) (rate(node_cpu_seconds_total{mode!~"idle|iowait|steal"}[2m]))
          /
          sum without(mode) (rate(node_cpu_seconds_total{mode!="steal"}[2m]))
        ) > 0.9
      for: 15m
      labels:
        severity: info
    - alert: NodeCPUHighSteal
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        summary: Hypervisor is stealing more than 20% of guest CPU
      expr: |-
        sum without(mode) (
          avg without (cpu) (
            rate(node_cpu_seconds_total{mode="steal"}[2m])
          )
        ) > 0.2
      for: 15m
      labels:
        severity: info
    - alert: NodeSystemSaturation
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }}
        summary: System load per core is high
      expr: |-
        node_load1{job="node-exporter"}
        / count without (cpu, mode) (node_cpu_seconds_total{mode="idle"}) > 2
      for: 15m
      labels:
        severity: warning
    - alert: NodeMemoryMajorPagesFaults
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanize }}
        summary: Major page faults rate is more than 500
      expr: rate(node_vmstat_pgmajfault[5m]) > 500
      for: 15m
      labels:
        severity: warning
    - alert: NodeMemoryHighUtilization
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $value | humanizePercentage }}
        summary: Available memory is below 10%
      expr: |
        # ZFS ARC size is file cache but it isn't counted in MemAvailable
        (
          (node_memory_MemAvailable_bytes + node_zfs_arc_size or node_memory_MemAvailable_bytes)
          /
          node_memory_MemTotal_bytes
        ) < 0.1
      for: 60m
      labels:
        severity: warning
    - alert: NodeDiskIOSaturation
      annotations:
        description: >-
          {{ $labels.instance }}:
          device {{ $labels.device }}:
          {{ $value | humanize }}
        summary: Disk IO queue (aqu-sq) is above 10
      expr: |-
        (
          rate(node_disk_io_time_weighted_seconds_total{device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m])
        ) > 10
      for: 30m
      labels:
        severity: warning
    - alert: NodeSystemdServiceFailed
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.name }}
        summary: Systemd service has failed
      expr: node_systemd_unit_state{state="failed"} == 1
      for: 5m
      labels:
        severity: warning
    - alert: NodeBondingDegraded
      annotations:
        description: >-
          {{ $labels.instance }}:
          interface {{ $labels.master }}:
          {{ $value }} failed slaves
        summary: Bonding interface is degraded
      expr: (node_bonding_slaves - node_bonding_active) != 0
      for: 5m
      labels:
        severity: warning
    - alert: NodeUnexpectedCpuMode
      annotations:
        description: >-
          {{ $labels.instance }}:
          {{ $labels.mode }}
        summary: Node CPU mode is not expected
      expr: node_cpu_seconds_total{mode!~"system|user|nice|iowait|softirq|irq|idle|steal|interrupt"}
      for: 5m
      labels:
        severity: warning
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alert-node-zfs-pool
  labels:
    prometheus.io/instance: main
    instance.prometheus.io/main: enable
    instance.prometheus.io/prompp: enable
spec:
  groups:
  - name: alert-node-zfs-pool
    rules:
    - alert: NodeZfsPoolNotOnline
      expr: node_zfs_zpool_state{state!="online"} > 0
      for: 0m
      labels:
        severity: critical
      annotations:
        summary: ZFS pool state is not online
        description: >-
          {{ $labels.instance }}:
          pool {{ $labels.zpool }}:
          {{ $labels.state }}
